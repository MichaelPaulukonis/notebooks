{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichaelPaulukonis/notebooks/blob/main/min_dalle_(version).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WL-G_f2_ld8"
      },
      "source": [
        "# min(DALLÂ·E)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwX6RmWsZRe3"
      },
      "outputs": [],
      "source": [
        "#@title Save to Google Drive\n",
        "#@markdown Will save your results to Google Drive - image and prompt+settings\n",
        "\n",
        "save_to_google_drive = True  #@param {type: \"boolean\"}\n",
        "\n",
        "if save_to_google_drive:\n",
        "  from google.colab import drive\n",
        "  import time\n",
        "  \n",
        "  #@title Google Colab Google Drive Downloader Thing { vertical-output: true }\n",
        "  Target_Folder = \"/content/drive/MyDrive/colab_out/\" #@param {type:\"string\"}\n",
        "  drive.mount('/content/drive')\n",
        "  \n",
        "  !mkdir -p $Target_Folder\n",
        "\n",
        "  save_prompt = True  #@param {type: \"boolean\"}\n",
        "  prompt_file = \"/content/drive/MyDrive/colab_out/prompts.txt\" #@param {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zl_ZFisFApeh"
      },
      "source": [
        "### Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "ix_xt4X1_6F4"
      },
      "outputs": [],
      "source": [
        "! nvidia-smi\n",
        "! pip install min-dalle==0.4.7\n",
        "! pip install Pillow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kViq2dMbGDKt"
      },
      "source": [
        "### Load Model\n",
        "`float32` is faster than `float16` but uses more GPU memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8W-L2ICFGFup"
      },
      "outputs": [],
      "source": [
        "dtype = \"float16\" #@param [\"float32\", \"float16\"]\n",
        "from IPython.display import display, update_display\n",
        "import torch\n",
        "from min_dalle import MinDalle\n",
        "\n",
        "model = MinDalle(\n",
        "    dtype=getattr(torch, dtype),\n",
        "    device='cuda',\n",
        "    is_mega=True, \n",
        "    is_reusable=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c52TV1GbBNgS"
      },
      "source": [
        "### Generate Images\n",
        "\n",
        "- `image_prefix` name of the images (if you're saving to Google Drive)\n",
        "\n",
        "- `progressive_outputs` Whether to show intermediate output.  Adds a small delay and increases memory usage.\n",
        "\n",
        "- `seamless` Tiles the images in token space instead of pixel space\n",
        "\n",
        "- `grid_size` Size of the image grid.  Reduce this if you run out of GPU memory.\n",
        "\n",
        "- `batch_size` Number of images to generate. If you're not saving to GDrive, this is somewhat pointless.\n",
        "\n",
        "- `temperature` High temperature increases the probability of sampling low scoring image tokens.\n",
        "\n",
        "- `supercondition_factor` Higher values result in better agreement with the text but a narrower variety of generated images\n",
        "\n",
        "- `top_k` Each image token is sampled from the top $k$ most probable tokens\n",
        "\n",
        "- `use_random_seed` Using the built-in random seed results in different images each time. Set manually to get results starting from the same seed. If running in batch mode `use_random_seed` is silently enabled.\n",
        "\n",
        "- `manual_seed` An integer from 1 to 10,000. If running in batch mode `manual_seed` is ignored.\n",
        "\n",
        "- `is_verbose` min-dalle will print out extra internal data (mostly about text tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQ0UG05dA4p2"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "text = \"vibrant popart screenprint of a human anatomical chart diagram with labels, by Andy Warhol; strong bold solid dayglo colors, popart, deep vibrant intense contrasty color\" #@param {type:\"string\"}\n",
        "if save_to_google_drive:\n",
        "  image_prefix = \"tests\" #@param {type:\"string\"}\n",
        "progressive_outputs = False #@param {type:\"boolean\"}\n",
        "seamless = False #@param {type:\"boolean\"}\n",
        "grid_size =  1 #@param {type:\"integer\"}\n",
        "batch_size = \"2\" #@param [1,2,3,4,5,6,7,8,9,10,15,20]\n",
        "temperature = 16 #@param {type:\"slider\", min:0.01, max:16, step:0.01}\n",
        "supercondition_factor =  \"64\" #@param [4, 8, 16, 32, 64]\n",
        "top_k =  \"4\" #@param [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]\n",
        "use_random_seed = False #@param {type:\"boolean\"}\n",
        "if not use_random_seed:\n",
        "  manual_seed = 14 #@param {type:\"integer\"}\n",
        "is_verbose = False #@param {type:\"boolean\"}\n",
        "\n",
        "batch_size = int(batch_size)\n",
        "if batch_size > 1: use_random_seed = True\n",
        "\n",
        "if save_to_google_drive:\n",
        "  !mkdir -p '{Target_Folder}/{image_prefix}'\n",
        "\n",
        "if save_prompt:\n",
        "  with open(prompt_file, 'a') as f:\n",
        "    f.write(f'{text} {{ temp: {temperature}, sf: {supercondition_factor} top_k: {top_k}, start: {time.strftime(\"%Y%m%d-%H%M%S\")} }}\\n')\n",
        "\n",
        "for x in range(0, batch_size):\n",
        "  image = model.generate_image(\n",
        "      text=text,\n",
        "      seed= -1 if use_random_seed else manual_seed,\n",
        "      grid_size=grid_size,\n",
        "      is_seamless=seamless,\n",
        "      temperature=temperature,\n",
        "      top_k=int(top_k),\n",
        "      supercondition_factor=float(supercondition_factor),\n",
        "      is_verbose=is_verbose\n",
        "  )\n",
        "\n",
        "  if batch_size > 1:\n",
        "    print(f\"\\r{x+1} of {batch_size}\")\n",
        "\n",
        "  display_image = display if (x == 0) else update_display\n",
        "  display_image(image, display_id=1)\n",
        "\n",
        "  if save_to_google_drive:\n",
        "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    image.save(f'{Target_Folder}/{image_prefix}/{image_prefix}_{timestr}_{temperature}_{supercondition_factor}_{top_k}.png')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "min-dalle (version)",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichaelPaulukonis/notebooks/blob/main/min_dalle_(version).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WL-G_f2_ld8"
      },
      "source": [
        "# min(DALLÂ·E)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwX6RmWsZRe3"
      },
      "outputs": [],
      "source": [
        "#@title Save to Google Drive\n",
        "#@markdown Will save your results to Google Drive - image and prompt+settings\n",
        "\n",
        "save_to_google_drive = True  #@param {type: \"boolean\"}\n",
        "\n",
        "if save_to_google_drive:\n",
        "  from google.colab import drive\n",
        "  import time\n",
        "  \n",
        "  #@title Google Colab Google Drive Downloader Thing { vertical-output: true }\n",
        "  Target_Folder = \"/content/drive/MyDrive/colab_out/\" #@param {type:\"string\"}\n",
        "  drive.mount('/content/drive')\n",
        "  \n",
        "  !mkdir -p $Target_Folder\n",
        "\n",
        "  save_prompt = True  #@param {type: \"boolean\"}\n",
        "  prompt_file = \"/content/drive/MyDrive/colab_out/prompts.txt\" #@param {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zl_ZFisFApeh"
      },
      "source": [
        "### Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "ix_xt4X1_6F4"
      },
      "outputs": [],
      "source": [
        "! nvidia-smi\n",
        "! pip install min-dalle==0.4.7\n",
        "! pip install Pillow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kViq2dMbGDKt"
      },
      "source": [
        "### Load Model\n",
        "`float32` is faster than `float16` but uses more GPU memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8W-L2ICFGFup"
      },
      "outputs": [],
      "source": [
        "dtype = \"float16\" #@param [\"float32\", \"float16\"]\n",
        "from IPython.display import display, update_display\n",
        "import torch\n",
        "from min_dalle import MinDalle\n",
        "\n",
        "model = MinDalle(\n",
        "    dtype=getattr(torch, dtype),\n",
        "    device='cuda',\n",
        "    is_mega=True, \n",
        "    is_reusable=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c52TV1GbBNgS"
      },
      "source": [
        "### Generate Images\n",
        "\n",
        "- `image_prefix` name of the images (if you're saving to Google Drive)\n",
        "\n",
        "- `progressive_outputs` Whether to show intermediate output.  Adds a small delay and increases memory usage.\n",
        "\n",
        "- `seamless` Tiles the images in token space instead of pixel space\n",
        "\n",
        "- `grid_size` Size of the image grid.  Reduce this if you run out of GPU memory.\n",
        "\n",
        "- `batch_size` Number of images to generate. If you're not saving to GDrive, this is somewhat pointless.\n",
        "\n",
        "- `temperature` High temperature increases the probability of sampling low scoring image tokens.\n",
        "\n",
        "- `supercondition_factor` Higher values result in better agreement with the text but a narrower variety of generated images\n",
        "\n",
        "- `top_k` Each image token is sampled from the top $k$ most probable tokens\n",
        "\n",
        "- `seed_behavior` Random creates a new random number for each image in batch. Iter will increment by 1. Fixed will stay the same. Really only useful if you add extra coding to modify other params in batch mode.\n",
        "\n",
        "- `seed` Using the built-in random seed results in different images each time. Set manually to get results starting from the same seed. An integer from 1 to 2**32 - 1. Use -1 for random.\n",
        "\n",
        "- `is_verbose` min-dalle will print out extra internal data (mostly about text tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQ0UG05dA4p2"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from types import SimpleNamespace\n",
        "\n",
        "def DalleArgs():\n",
        "  text = \"anatomical medical illustration chart diagram+screenprint by robert rauschenberg+strong dayglo colors\" #@param {type:\"string\"}\n",
        "  if save_to_google_drive:\n",
        "    image_prefix = \"rauschenberg.1016\" #@param {type:\"string\"}\n",
        "  progressive_outputs = False #@param {type:\"boolean\"}\n",
        "  seamless = False #@param {type:\"boolean\"}\n",
        "  grid_size =  3 #@param {type:\"integer\"}\n",
        "  batch_size = \"2\" #@param [1,2,3,4,5,6,7,8,9,10,15,20]\n",
        "  temperature = 2.17 #@param {type:\"slider\", min:0.01, max:16, step:0.01}\n",
        "  supercondition_factor =  \"64\" #@param [4, 8, 16, 32, 64]\n",
        "  top_k =  \"4\" #@param [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]\n",
        "  seed_behavior = \"iter\" #@param [\"iter\",\"fixed\",\"random\"]\n",
        "  seed = -1 #@param {type:\"integer\"}\n",
        "  is_verbose = False #@param {type:\"boolean\"}\n",
        "\n",
        "  batch_size = int(batch_size)\n",
        "\n",
        "  return locals()\n",
        "\n",
        "args_dict = DalleArgs()\n",
        "args = SimpleNamespace(**args_dict)\n",
        "\n",
        "if save_to_google_drive:\n",
        "  !mkdir -p '{Target_Folder}/{args.image_prefix}'\n",
        "\n",
        "if args.seed == -1:\n",
        "    args.seed = torch.randint(0,2**32 - 1,(1,))[0].item()\n",
        "\n",
        "def next_seed(args):\n",
        "    if args.seed_behavior == 'iter':\n",
        "        args.seed += 1\n",
        "    elif args.seed_behavior == 'fixed':\n",
        "        pass # always keep seed the same\n",
        "    else:\n",
        "        args.seed = torch.randint(0,2**32 - 1,(1,))[0].item()\n",
        "    return args.seed\n",
        "\n",
        "if save_prompt:\n",
        "  with open(prompt_file, 'a') as f:\n",
        "    f.write(f'{args.text} {{ temp: {args.temperature}, sf: {args.supercondition_factor} top_k: {args.top_k}, seed: {args.seed}, start: {time.strftime(\"%Y%m%d-%H%M%S\")} }}\\n')\n",
        "\n",
        "for x in range(0, args.batch_size):\n",
        "  print(f\"{x+1} of {args.batch_size} temp: {args.temperature} seed: {args.seed}\")\n",
        "\n",
        "  image = model.generate_image(\n",
        "      text=args.text,\n",
        "      seed=args.seed,\n",
        "      grid_size=args.grid_size,\n",
        "      is_seamless=args.seamless,\n",
        "      temperature=args.temperature,\n",
        "      top_k=int(args.top_k),\n",
        "      supercondition_factor=float(args.supercondition_factor),\n",
        "      is_verbose=args.is_verbose\n",
        "  )\n",
        "\n",
        "  display(image)\n",
        "\n",
        "  if save_to_google_drive:\n",
        "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    image.save(f'{Target_Folder}/{args.image_prefix}/{args.image_prefix}_{timestr}_{args.temperature}_{args.supercondition_factor}_{args.top_k}.png')\n",
        "\n",
        "  seed = next_seed(args)\n",
        "  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}